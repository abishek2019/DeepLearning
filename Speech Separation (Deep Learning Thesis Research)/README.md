<h2>Speech Separation with Generative Adversarial Networks (GANs)</h2><p> In this research, the speech separation task was performed with the Libri2Mix dataset. Major contributions include:
 
 -  developed a speech separation model using a baseline [Conv-TasNet](https://arxiv.org/abs/1809.07454) as the generator and a deep convolutional network as the discriminator. <br>
-  incorporated GAN variants based on the objective functions (Vanilla GAN, Least Squares GAN, and Metric GAN) for model training.<br>
-  established a uniform evaluation framework to compare GAN performance over the baseline model. 
 <br><br>

 Certainly, here's a condensed version:

- Developed a speech separation model using Conv-TasNet as the generator and a deep convolutional network as the discriminator.
  
- Explored GAN variants (Vanilla GAN, LSGAN, Metric GAN) for model training.
  
- Established a uniform evaluation framework to compare GAN performance against the baseline model.
 Results from the baseline model and each of the GAN models are shown below (which depicts a small section of the waveform of a separated speech):

<a href="https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png">
<img src="https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png" alt="Alt text" width="1000" height="500">
</a>



