<h2>Exploring Speech Separation with GANs</h2> <hr>In this research, I:<br><br>
- designed a GAN architecture where a Fully-Convolutional Time-Domain Audio Separation Network (Conv-TasNet) model is used as the generator and a deep convolutional network is used as the discriminator. 
- incorporated different GAN variants based on the objective functions, including Vanilla GAN, Least Squares GAN (LSGAN), and Metric GAN, for model training.
- developed a uniform comparison framework for comparing and evaluating the performance of GANs in the speech separation task. 
â€‹
Results from the baseline model (nonGAN) and each of the GAN models are shown below, which depict small sections of waveforms of a separated source: 
![alt text](https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png?raw=true)
<br>
