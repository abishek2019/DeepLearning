<h2>Exploring Speech Separation with GANs</h2><p> In this research, I:<br><br> 
 -  designed a Generative Adversarial Network (GAN) using a Fully-Convolutional Time-Domain Audio Separation Network (Conv-TasNet) model as the generator and a deep convolutional network as the discriminator. <br><br>
-  incorporated different GAN variants based on the objective functions, including Vanilla GAN, Least Squares GAN (LSGAN), and Metric GAN, for model training.<br><br>
-  developed a uniform comparison framework for comparing and evaluating the performance of GANs in the speech separation task. 
â€‹
 

Results from the baseline model and each of the GAN models are shown below, which depict small sections of waveforms of a separated source: 
![alt text](https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png?raw=true)
<br>
