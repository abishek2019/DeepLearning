<h2>Exploring Speech Separation with GANs</h2> <hr>In this research, I:<br>
- Designed a GAN architecture where a Fully-Convolutional Time-Domain Audio Separation Network (Conv-TasNet) model is used as the generator and a deep convolutional network is used as the discriminator. 
- I developed a uniform comparison framework for assessing the performance of Generative Adversarial Networks (GANs) in the speech separation task. 
	using the Libri2Mix dataset

Develop a uniform/common comparison framework (all use GAN, and CNN as the discriminator) to compare and evaluate the effectiveness of GAN/CNN in speech separation. ​

​

The best performing GAN model:  Abi-MetricGAN, improves over the baseline Conv-TasNet by sizeable amount.​

​
	
Results from the baseline model (nonGAN) and each of the GAN models are shown below, which depict small sections of waveforms of a separated source: 
![alt text](https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png?raw=true)
<br>
