<h2>Exploring Speech Separation with GANs</h2> <hr><p> This research explores the performance of Generative Adversarial Networks (GANs) in the speech separation task using the Libri2Mix dataset. A Fully-Convolutional Time-Domain Audio Separation Network (Conv-TasNet) model is used as the generator and a deep convolutional network is used as the discriminator. Different GAN variants based on the objective functions, including Vanilla GAN, Least Squares GAN (LSGAN), and Metric GAN, are incorporated for model training.
	
Results from the baseline model (nonGAN) and each of the GAN models are shown below, which depict small sections of waveforms of a separated source: 
![alt text](https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png?raw=true)
<br>
