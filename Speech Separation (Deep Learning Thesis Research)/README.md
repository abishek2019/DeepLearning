<h2>Exploring Speech Separation with Generative Adversarial Networks (GANs)</h2><p> In this research, I performed the speech separation task using the Libri2Mix dataset. My major contributions include:<br><br> 
 -  designed a speech separation model using a Fully-Convolutional Time-Domain Audio Separation Network (Conv-TasNet) as the generator and a deep convolutional network as the discriminator. <br><br>
-  incorporated different GAN variants based on the objective functions, including Vanilla GAN, Least Squares GAN (LSGAN), and Metric GAN, for model training.<br><br>
-  developed a uniform comparison framework for comparing and evaluating the performance of GANs over the baseline model (nonGAN). 

 <br><br>
Results from the baseline model and each of the GAN models are shown below (which depicts a small section of the waveform of a separated speech): 
![alt text](https://github.com/abishek2019/Machine_Learning/blob/main/Speech%20Separation%20(Deep%20Learning%20Thesis%20Research)/assets/Result2.png?raw=true)
<br>
